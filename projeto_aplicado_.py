# -*- coding: utf-8 -*-
"""Projeto Aplicado .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18AMuL142hr-eptbQGZ_A37kjH-w1L7e2
"""

# Instalando o yahoo finance
!pip install yfinance --upgrade --no-cache-dir

!pip install requests

"""# **Importação dos Pacotes**"""

import pandas as pd
import numpy as np
import yfinance as yf #Instalando e importando a API no código
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

import requests
url = "https://investnews.com.br/financas/veja-a-lista-completa-dos-bdrs-disponiveis-para-pessoas-fisicas-na-b3/"
r = requests.get(url)
html = r.text
df_nomes_tickers = pd.read_html(html, header=0)[0]
df_nomes_tickers.tail(10)

with pd.option_context('display.max_rows',10):
  print(df_nomes_tickers)

dados_series = yf.download(["MMMC34.SA"], start="2018-01-01", end="2022-01-01")

#Selecionar apenas os dados referentes ao preço de fechamento
df = dados_series.drop(['Open','High', 'Low', 'Adj Close', 'Volume'], axis=1)

df.head()

df['Close']

y=[]
for a in df['Close']:
  y.append(a)

y

x = np.arange (1,len(y)+1,1)

"""**padronização dos dados**"""

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

import matplotlib.pyplot as plt
plt.title('Série Temporal - Normalizada')
plt.xlabel('Período')
plt.ylabel('Valor')
plt.plot(x,y)
plt.show()

"""**Preparação dos conjuntos de dados de treinamento e de teste**"""

percentual_treinamento = 0.8
qtd_treinamento = int(percentual_treinamento*(len(x)));

x_treino = x[0:qtd_treinamento] 
x_teste = x[qtd_treinamento:]

y_treino = y[0:qtd_treinamento]
y_teste = y[qtd_treinamento:]

treino = np.array(list(zip(x_treino, y_treino)))
teste = np.array(list(zip(x_teste, y_teste)))
for i in range(5):
  print('treino[{}]: {}'.format(i+1, treino[i]))

"""**Organização do modelo de dados**"""

def create_dataset(n_X, look_back):
  dataX = []
  dataY = []
  for i in range(len(n_X)-look_back):
    a = n_X[i:(i+look_back), ]
    print('a: {}'.format(a))
    dataX.append(a)
    dataY.append(n_X[i + look_back, ])
  print('dataX: {}'.format(dataX))
  return np.array(dataX), np.array(dataY)

def preparar_dados(dados_serie, look_back):
  X, y =[],[]
  n = len(dados_serie)
  for i in range(n - look_back):
    posicao_fim = i + look_back
    if posicao_fim <= n:
      seq_x = dados_serie[i:posicao_fim,1]
      seq_y = dados_serie[posicao_fim,1]
      X.append(seq_x)
      y.append(seq_y)
  return np.array(X), np.array(y)

"""**Visualização da estruturação dos dados**"""

look_back = 1
x_treino, y_treino = preparar_dados(treino, look_back)
x_teste, y_teste = preparar_dados(teste, look_back)

n_caracteristicas = 1 #série monovariada
x_treino = x_treino.reshape((x_treino.shape[0], 
                             x_treino.shape[1], 
                             n_caracteristicas))
x_teste = x_teste.reshape((x_teste.shape[0], 
                       x_teste.shape[1], 
                       n_caracteristicas))

#print('ax: {}'.format(trainx))
#print('y: {}'.format(y))
for i in range(5):
  print('treino[{}]: {} -> {}'.format(i+1, x_treino[i], y_treino[i]))

"""**Criação do Modelo de Redes Neurais**"""

import tensorflow as tf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
n_etapas = x_treino.shape[1]
n_caracteristicas = x_treino.shape[2]
epocas = 20
n_unidades = 100
tf.random.set_seed(8888) # Setting seed to ensure reproducibility.
modelo = Sequential()
camada_de_entrada=(n_etapas, n_caracteristicas)
modelo.add(LSTM(n_unidades, 
               return_sequences = True, 
               input_shape = camada_de_entrada))
modelo.add(Dropout(0.2))
modelo.add(LSTM(128,
               input_shape = camada_de_entrada))
modelo.add(Dense(1))

modelo.summary()

modelo.compile(loss = 'mean_squared_error', 
              optimizer = 'adam')

historico = modelo.fit(x_treino, y_treino,
                       epochs = epocas,
                       batch_size = 70,
                       verbose = False,
                       shuffle = False,
                       validation_split = 0.3)

import pandas as pd
hist = pd.DataFrame(historico.history)
hist.head()

loss = modelo.evaluate(x_teste, y_teste, batch_size=64)
print("loss: {}".format(loss))

plt.title('Cálculo do Erro ao longo do treinamento')
plt.ylabel('Erro')
plt.xlabel('Época')
plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.legend(['loss (treinamento)', 'val_loss (validação)'], loc='upper right')
plt.show()

predicao = modelo.predict(x_teste)

look_back = 1
valores_reais_y = y_teste
plt.figure(figsize=(50,10))
plt.plot(list(range(len(valores_reais_y))), 
         valores_reais_y, 
         marker='.', 
         label="Real")
lst_dados_predicao=[w[0] for w in predicao]
plt.plot(list(np.arange(len(predicao))-look_back), 
         lst_dados_predicao, 
         'r',label="Estimação do Modelo")
plt.ylabel('valores', size=15)
plt.xlabel('período', size=15)
plt.legend(fontsize=15)
plt.show()

len(valores_reais_y)

len(lst_dados_predicao)

n=len(x_teste)
x_teste[n-1] #lembrar que no Python a indexação começa na posição 0

minha_predicao = modelo.predict([x_teste[n-1]])

print(f'minha predição é: {minha_predicao}')

"""## PREDIZENDO MAIS VALORES"""

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["ABUD34.SA"], start="2022-01-01", end="2022-01-05")

new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)

new_data

new_data.head()

new_data['Close']

y=[]
for a in new_data['Close']:
  y.append(a)

y

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

predicted_data = modelo.predict(new_data)

# denormalize the predicted data
predicted_data_2 = predicted_data * (maximo - minimo) + minimo

# print the predicted stock prices
print(predicted_data_2)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["XPBR31.SA"], start="2022-01-01", end="2022-01-05")

new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)

new_data

new_data['Close']

y=[]
for a in new_data['Close']:
  y.append(a)

y

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_3 = predicted_data * (maximo - minimo) + minimo

print(predicted_data_3)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["COCA34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_4 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_4)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["COLG34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_5 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_5)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["MSCD34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_6 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_6)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["NIKE34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_7 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_7)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["ORCL34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_8 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_8)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["RYTT34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_9 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_9)

# assume `dados_series` contains the new stock prices data
dados_series = yf.download(["USBC34.SA"], start="2022-01-01", end="2022-01-05")
new_data = dados_series.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)
new_data
new_data['Close']
y=[]
for a in new_data['Close']:
  y.append(a)

x = np.arange (1,len(y)+1,1)

minimo = np.min(y)
maximo = np.max(y)
y = (y - minimo)/(maximo - minimo)

# use the trained model to predict the new stock prices
predicted_data = modelo.predict(new_data)

predicted_data_10 = predicted_data * (maximo - minimo) + minimo
print(predicted_data_10)

"""### APLICANDO A MOCHILA"""

P10 = predicted_data_10.ravel().tolist()
P10 =P10[0] 
P10

P9 = predicted_data_9.ravel().tolist()
P9 =P9[0] 
P9

P8 = predicted_data_8.ravel().tolist()
P8 =P8[0] 
P8

P7 = predicted_data_7.ravel().tolist()
P7 =P7[0] 
P7

P6 = predicted_data_6.ravel().tolist()
P6 =P6[0] 
P6

P5 = predicted_data_5.ravel().tolist()
P5 =P5[0] 
P5

P4 = predicted_data_4.ravel().tolist()
P4 =P4[0] 
P4

P3 = predicted_data_3.ravel().tolist()
P3 =P3[0] 
P3

P2 = predicted_data_2.ravel().tolist()
P2 =P2[0] 
P2

P1 = minha_predicao.ravel().tolist()
P1=P1[0]
P1

!pip install mip

from mip import Model, maximize, xsum, CBC, BINARY, OptimizationStatus

coef_funcao_objetivo = [P1,P2,P3,P4,P5,P6,P7,P8,P9,P10]

coef_funcao_objetivo = [P1,P2,P3,P4,P5,P6,P7,P8,P9,P10]
coef_restr = [1, 2, 3, 4, 5, 6,7,8,9,10]
termo_independente = 3

I = range(len(coef_funcao_objetivo))
m = Model("knapsack")

x = [m.add_var(var_type=BINARY) for i in I]

m.objective = maximize(xsum(coef_funcao_objetivo[i] * x[i] for i in I))

m += xsum(coef_restr[i] * x[i] for i in I) <= termo_independente
print(f'O modelo tem {m.num_cols} variável(eis), {m.num_rows} restrição(ões) e {m.num_nz} zero(s)')

status = m.optimize(max_seconds=2)

status == OptimizationStatus.OPTIMAL

itens_selecionados = ["x"+str(i+1) for i in I if x[i].x >= 0.99]
print("Itens selecionados: {}".format(itens_selecionados))

P3

